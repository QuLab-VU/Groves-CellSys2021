---
title: "Single Cell SCLC Cell Line Archetypes"
output: html_notebook
---
The purpose of the notebook is to apply PCHA to the single cell cell line data. 

```{r include = FALSE}
library(reticulate)
reticulate::use_condaenv("/Users/smgroves/Documents/anaconda3/envs/mazebox_env", conda = "auto", required = TRUE) # set TRUE to force R to use reticulate_PCHA
if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

# BiocManager::install("sva")
# install.packages("devtools")
# devtools::install_local("/Users/smgroves/Downloads/CytoTRACE-master.zip")
# library(CytoTRACE)
# BiocManager::install("scater")
library(scater)
# install loomR from GitHub using the remotes package 
# remotes::install_github(repo ='mojaveazure/loomR', ref = 'develop')
library(loomR)
# install.packages('Seurat')
library(Seurat)
# remotes::install_github("mojaveazure/seurat-disk")
# library(SeuratData)
library(SeuratDisk)


```

# Read single cell data 
Reading in preprocessed (MAGIC imputed) data from from `2-Human_cell_lines_scPCHA.ipynb`

```{r message = FALSE}
file = "../../out/cell-lines/X_magic_scanorama_for_R.h5ad"
Convert(file, dest = "h5seurat", overwrite = TRUE)
data <- LoadH5Seurat("../../out/cell-lines/X_magic_scanorama_for_R.h5ad")
Idents(data) = data@meta.data$cline

# data <- JackStraw(data, num.replicate = 100)
# data <- ScoreJackStraw(data, dims = 1:20)
# JackStrawPlot(data, dims = 1:20) ##this plot indicates that the top 18 PCs should be kept.

ElbowPlot(data) #this plot indicates  the top 8 are important, so we'll take the larger number-18- to be safe.
DimPlot(data, reduction = "pca", label = TRUE)

data <- FindNeighbors(data, dims = 1:10)
data <- FindClusters(data, resolution = 0.5)
data <- RunUMAP(data, dims = 1:10)
DimPlot(data, reduction = "umap")

```


# Plot important SCLC Genes and add cell line labels

```{r}
data[["louvain"]] <- Idents(object = data) #store louvain Idents
Idents(object = data) <- data@meta.data$cline #add cell line labels

DimPlot(data, label = TRUE) 
VlnPlot(data, features = c("ASCL1", "YAP1", "POU2F3", 'CALCA','NEUROD2', 'MYC'), combine = FALSE)
```

# Plotting the data

```{r pca-umap-plots}

# install.packages('plotly')

# Load plot_ly
library(plotly)

# Extract tSNE information from Seurat Object
pca_1 <- data[["pca"]]@cell.embeddings[,1]
pca_2 <- data[["pca"]]@cell.embeddings[,2]
pca_3 <- data[["pca"]]@cell.embeddings[,3]

# Visualize what headings are called so that you can extract them to form a dataframe
# Embeddings(object = data, reduction = "pca")
plot.data <- FetchData(object = data, vars = c("PC_1", "PC_2", "PC_3", "cline"))
plot.data$label <- paste(rownames(plot.data))
plot_ly(data = plot.data, 
        x = ~PC_1, y = ~PC_2, z = ~PC_3, 
        color = ~cline, 
        colors = c("lightseagreen",
                   "green",
                   "red",
                   "orange1",
                   "royalblue1",
                   "lightcyan3",
                   "peachpuff3",
                   "darkorchid1",
                   "turquoise",
                   "darkmagenta"),
        type = "scatter3d", 
        mode = "markers", 
        marker = list(size = 5, width=2), # controls size of points
        text=~label, #This is that extra column we made earlier for which we will use for cell ID
        hoverinfo="text") #When you visualize your plotly object, hovering your mouse pointer over a point shows cell names

VizDimLoadings(data, dims = 1:3, reduction = "pca")

```

## Save files
```{r}

save(data, file="../../out/cell-lines/ParetoTI/X_magic_scanorama_for_ParetoTI.Robj")

write.csv(data[["RNA"]]@scale.data, '../../out/cell-lines/ParetoTI/integrated-corrected-data_scanorama.csv')
write.csv(data[['pca']]@cell.embeddings, '../../out/cell-lines/ParetoTI/pca_embedding_scanorama.csv')
write.csv(data[['pca']]@feature.loadings, '../../out/cell-lines/ParetoTI/pca_feature_loadings_scanorama.csv')

data <- ProjectDim(data, reduction = 'pca')
write.csv(data[['pca']]@feature.loadings.projected, '../../out/cell-lines/ParetoTI/pca_feature_loadings_projected_scanorama.csv')

# devtools::install_github(repo = 'hhoeflin/hdf5r')
# devtools::install_github(repo = 'mojaveazure/loomR', ref = 'develop')
# devtools::install_github(repo = 'satijalab/seurat', ref = 'loom')
# library(loomR)
# 
# data.loom <- as.loom(data, filename = "X_magic_for_ParetoTI.loom", verbose = FALSE)
```

# Archetypal Analysis

We will now apply the archetype analysis to the single cell data. Since we've reduced the PCs to 10, we have gotten rid of a lot of the noise and still captured a large proportion of the variance. 

## Choosing number of archetypes

Fit to k = 2 to 8 to find the best number of archetypes. We will look at the variance explained by each archetype as well as the t-ratios. To choose a final number to move forward with the analysis, we will run a randomization test to get a p-value for each number of archetypes (t-ratio test). 
```{r}

library(ParetoTI)
library(cowplot)
library(ggplot2)
library(RColorBrewer)
library(reshape2)
library(factoextra)
library(ggfortify)
library(cluster)
# install.packages("data.table")
##################################
# load(file="../../out/cell-lines/ParetoTI/X_magic_scanorama_for_ParetoTI.Robj")

x <- data[["RNA"]]@scale.data

x_pca <- read.csv('../../out/cell-lines/ParetoTI/pca_embedding_scanorama.csv',header = TRUE,row.names = 1)
x_pca <- t(x_pca)

x_pca <- x_pca[1:10,] #keep only top 10 PCs
loadings<- read.csv('../../out/cell-lines/ParetoTI/pca_feature_loadings_projected_scanorama.csv', header = TRUE, row.names = 1)
loadings <- as.matrix(loadings)

arc_ks = k_fit_pch(x_pca, ks = 2:8, check_installed = T,
                   bootstrap = T, bootstrap_N = 200, maxiter = 1000,
                   bootstrap_type = "m", seed = 2543, 
                   volume_ratio = "t_ratio", # set to "none" if too slow
                   delta=0, conv_crit = 1e-04, order_type = "align",
                   sample_prop = 0.75)

# Show variance explained by a polytope with each k (cumulative)
plot_arc_var(arc_ks, type = "varexpl", point_size = 2, line_size = 1.5) + theme_bw()
plot_arc_var(arc_ks, type = "res_varexpl", point_size = 2, line_size = 1.5) + theme_bw()
plot_arc_var(arc_ks, type = "total_var", point_size = 2, line_size = 1.5) +
  theme_bw() +
  ylab("Mean variance in position of vertices")
plot_arc_var(arc_ks, type = "t_ratio", point_size = 2, line_size = 1.5) + theme_bw()

```

## T-ratio

```{r}
for(i in 4:6){  
  arc <- fit_pch(x_pca, noc = i, delta = 0, conv_crit = 1e-04, maxiter = 500)
  
  start = Sys.time()
  pch_rand = randomise_fit_pch(x_pca, arc_data = arc,
                               n_rand = 1000,
                               replace = FALSE, bootstrap_N = NA,
                               volume_ratio = "t_ratio",
                               maxiter = 500, delta = 0, conv_crit = 1e-4,
                               type = "m", clust_options = list(cores = 3))
  # use type m to run on a single machine or cloud
  # type = "m", clust_options = list(cores = 3))
  # use clustermq (type cmq) to run as jobs on a computing cluster (higher parallelisation)
  # type = "cmq", clust_options = list(njobs = 10)) 
  

  pdf(sprintf('../../figures/ParetoTI/%s_t-ratio_test_scanorama.pdf', i))
  plot.r_pch_fit(pch_rand, type = c("t_ratio"), nudge_y = 5)
  dev.off()
    # This analysis took:
  print(Sys.time() - start)
  print(pch_rand)
}

```

# Fitting archetypes using PCHA
``` {r}

##################################

# Fit 5 archetypes with bootstrapping for robustness 
arc_rob = fit_pch_bootstrap(x_pca, n = 200, sample_prop = .8, seed = 2543, delta = 1,
                            noc = 5)
arc_ave <- average_pch_fits(arc_rob)
save(arc, file="../int/arc_scanorama.Robj")
save(arc_rob, file="../int/arc_rob_scanorama.Robj")
save(arc_ave, file="../int/arc_ave_scanorama.Robj")
write.csv(arc$XC, file="../int/arc_positions_pca_scanorama.csv")
write.csv(arc_ave$XC, file="../int/arc_ave_positions_pca_scanorama.csv")

reconstruct_from_pca <- function(x, loadings, arc_XC, nComp = 18){
    mu = colMeans(t(x))
    Xhat = t(arc_XC[1:nComp,]) %*% t(loadings[,1:nComp])
    Xhat = scale(Xhat, center = -mu, scale = FALSE)
    return(Xhat)}

arc_genespace <- reconstruct_from_pca(data = x, pca = x_pca, arc_XC = t(arc_ave$XC))
write.csv(t(arc_genespace), '../data/single-cell/arc_gene-space_scanorama.csv')
##################################

load(file="../int/single-cell/arc_scanorama.Robj")
load( file="../int/single-cell/arc_rob_scanorama.Robj")
load( file="../int/single-cell/arc_ave_scanorama.Robj")


cols <- c(brewer.pal(9, "Set1"),'gray')

plot_arc(arc_data = arc, data = x_pca,
                   which_dimensions = 1:2,colors = cols,
                  data_lab = as.character(Idents(data))) + theme_bw()
p_pca = plot_arc(arc_data = arc, data = x_pca, 
                 which_dimensions = 1:3, line_size = 1.5,
                 colors = cols,
                  data_lab = as.character(Idents(data)),
                 text_size = 60, data_size = 2) 
plotly::layout(p_pca, title = "Archetypes for Top 18 PCs")

plasticity <- "/Users/smgroves/Documents/pycharm_workspace/archetypes/code/adata_R_plasticity.csv"
plas <- read.csv(plasticity,header = TRUE,row.names = 1)
plas[plas > .5] <- .5
p_pca = plot_arc(arc_data = arc_rob, data = x_pca, 
                 which_dimensions = 1:3, line_size = 1.5,
                  data_lab = as.numeric(plas$log1p_plasticity),
                 text_size = 60, data_size = 4) 
plotly::layout(p_pca, title = "Average Archetypes for Top 18 PCs")
htmlwidgets::saveWidget(p_pca, "plasticity.html")

pheno <- "/Users/smgroves/Documents/pycharm_workspace/archetypes/code/phenotype_S.csv"
phen <- read.csv(pheno,header = TRUE,row.names = 1)
p_pca = plot_arc(arc_data = arc_rob, data = x_pca, 
                 which_dimensions = 1:3, line_size = 1.5,colors = cols,
                  data_lab = as.character(phen$Phenotype_S),
                 text_size = 60, data_size = 2) 
plotly::layout(p_pca, title = "Average Archetypes for Top 18 PCs")
htmlwidgets::saveWidget(p_pca, "robust_archetypes.html")


pheno <- "/Users/smgroves/Documents/pycharm_workspace/archetypes/code/archetype_labels.csv"
phen <- read.csv(pheno,header = TRUE,row.names = 1)
phen <- phen[row.names(plas),]
p_pca = plot_arc(arc_data = arc_rob, data = x_pca, 
                 which_dimensions = 1:3, line_size = 1.5,colors = cols,
                  data_lab = as.character(phen),
                 text_size = 60, data_size = 2) 
plotly::layout(p_pca, title = "Average Archetypes for Top 18 PCs")

p_pca = plot_arc(arc_data = arc_ave, data = x_pca, 
                 which_dimensions = 1:3, line_size = 1.5,
                 data_lab = as.numeric(data[['RNA']]@data['GLI1',]),
                 text_size = 60, data_size = 3) 
plotly::layout(p_pca, title = "Expression of GLI1 in PCA")
htmlwidgets::saveWidget(p_pca, "GLI1.html")


p_pca = plot_arc(arc_data = arc_ave, data = x_pca, 
                 which_dimensions = 1:3, line_size = 1.5,
                 data_lab = as.numeric(data[['RNA']]@scale.data['NEUROD2',]),
                 text_size = 60, data_size = 3) 
plotly::layout(p_pca, title = "Expression of NEUROD2 in PCA")
htmlwidgets::saveWidget(p_pca, "NEUROD2.HTML")

p_pca = plot_arc(arc_data = arc_ave, data = x_pca, 
                 which_dimensions = 1:3, line_size = 1.5,
                 data_lab = as.numeric(data[['RNA']]@data['YAP1',]),
                 text_size = 60, data_size = 3) 
plotly::layout(p_pca, title = "Expression of YAP1 in PCA")
htmlwidgets::saveWidget(p_pca, "YAP1.html")

p_pca = plot_arc(arc_data = arc_ave, data = x_pca, 
                 which_dimensions = 1:3, line_size = 1.5,
                 data_lab = as.numeric(data[['RNA']]@data['POU2F3',]),
                 text_size = 60, data_size = 3) 
plotly::layout(p_pca, title = "Expression of POU2F3 in PCA")
htmlwidgets::saveWidget(p_pca, "POU2F3.html")

```

# Determine enriched genes and gene sets to define archetypes

This will be especially interesting for comparing archetypes 4 and 5, since it is pretty clear that the shape of the data is not clearly defined without an archetype at 5, but not many cells actually lie close to it. We use the ParetoTI package to evaulate gene sets enriched in each location. 

```{r}
library(matrixStats)

x.orig <- as.matrix(data[['RNA']]@data)

rownames(x.orig)<-gsub("-", ".", rownames(x.orig))



ix <- which(rownames(x.orig) %in%c('1.Sep','10.Sep','11.Mar','11.Sep','2.Sep','3.Mar','3.Sep','4.Mar','4.Sep','5.Sep', '5.Mar','6.Sep','6.Mar','7.Sep','7.Mar','8.Sep','8.Mar','9.Sep','9.Mar','RP11-206L10.1'))
ix <- which(rownames(x.orig) %in% c('7SK.1'))
clean <- x.orig[-ix, ]


activ_pi = measure_activity(as.matrix(x.orig), activity_method = 'pseudoinverse',# row names are assumed to be gene identifiers,
                         which = 'BP', return_as_matrix = F,
                         taxonomy_id = 9606, keytype = "ALIAS",
                         lower = 10, upper = 1000)
                         # aucell_options =list(aucMaxRank =
                          # nrow(as.matrix(x.orig)) * 0.05, binary = F, nCores = 3, plotStats = TRUE))
save(activ_pi, file="../int/activ_pi.Robj")

activ_pi <- within(activ_pi, rm('2__deoxyribonucleotide_biosynthetic_process','2__deoxyribonucleotide_metabolic_process','2_oxoglutarate_metabolic_process','3__phosphoadenosine_5__phosphosulfate_metabolic_process',
'3__UTR_mediated_mRNA_destabilization',
'3__UTR_mediated_mRNA_stabilization',
'7_methylguanosine_mRNA_capping',
'7_methylguanosine_RNA_capping',
'4_hydroxyproline_metabolic_process'))

activ_pi <- within(activ_pi, rm(`_de_novo__posttranslational_protein_folding`,
`_de_novo__protein_folding`,
`poly_A_+_mRNA_export_from_nucleus`))


data_attr = merge_arch_dist(arc_data = arc_ave, data = x_pca, 
                            feature_data = as.matrix(clean),
                            colData = activ_pi, 
                            dist_metric = c("euclidean", "arch_weights")[1],
                            colData_id = "cells", rank = F) 

enriched_genes = find_decreasing_wilcox(data_attr$data, data_attr$arc_col,
                                features = data_attr$features_col,
                                bin_prop = 0.05, method = "BioQC")
write.csv(enriched_genes, '../data/single-cell/enriched-genes.csv')

enriched_sets = find_decreasing_wilcox(data_attr$data, data_attr$arc_col,
                                features = data_attr$colData_col,
                                bin_prop = 0.05, method = "BioQC")

labs = get_top_decreasing(summary_genes = enriched_genes, summary_sets = enriched_sets,
                          cutoff_genes = 0.05,cutoff_sets = 0.05,
                          cutoff_metric = "wilcoxon_p_val", 
                          p.adjust.method = "fdr", 
                          order_by = "mean_diff", order_decreasing = T)

p_pca = plot_arc(arc_data = arc_ave, data = x_pca,
                 which_dimensions = 1:3, line_size = 1.5,
                 data_lab = activ_pi$lung_cell_differentiation,
                 text_size = 60, data_size = 6)
plotly::layout(p_pca, title = "lung_cell_differentiation activity")


enriched_genes_gam = find_decreasing(data_attr$data, data_attr$arc_col,
                                features = data_attr$features_col, return_only_summary = TRUE)
write.csv(enriched_genes_gam, '../data/single-cell/enriched_genes_gam.csv')

enriched_sets_gam = find_decreasing(data_attr$data, data_attr$arc_col,
                                features = data_attr$colData_col, return_only_summary = TRUE)
write.csv(enriched_sets_gam, '../data/single-cell/enriched_sets_gam.csv')



labs_gam = get_top_decreasing(summary_genes = enriched_genes_gam, summary_sets = enriched_sets_gam,
                          cutoff_genes = 0.05,cutoff_sets = 0.05,
                          cutoff_metric = "mean_prob", 
                          p.adjust.method = "none", 
                          order_by = "deriv50", order_decreasing = F,
                          min_max_diff_cutoff_g = .05)

fit_arc_gam_1('ASCL1', "archetype_2", data_attr)
```

## Save enrichments to be compared to bulk archetypes

The format we need the enrichment file in is a csv with the columns:
archetype #,Feature Name,P value (Mann-Whitney),Median Difference,Mean Difference,Significant after Benjamini-Hochberg correction?,Is first bin maximal?

```{r save-enriched}
# cutoff_metric = "wilcoxon_p_val", 
# p.adjust.method = "fdr", 
# order_by = "mean_diff"
```


# What direction are various mutation vectors facing? Can we uncover the driver mutations like Uri Alon has done?

# What is the difference between CORL279 and N+ cell lines? They seem to have the same shape, but CORL279 is translated (shifted) above N cell lines. Can we characterize that vector in PCA space? In archetype space?
We find the vector associated withthis shift by taking the difference of the averages of each cell line in PCA space (or archetype space). This should result in a vector pointing from one average to the other. We can then reconstruct these vectors in gene space to determine which genes are playing a major role in the difference between the two populations. 
```{r session-info}
session_info. = devtools::session_info()
session_info.
```

